{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22b93c9f-70dd-4ffe-8224-d86eb8b25ae0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting databricks-vectorsearch\n  Downloading databricks_vectorsearch-0.63-py3-none-any.whl.metadata (2.8 kB)\nCollecting deprecation>=2 (from databricks-vectorsearch)\n  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\nCollecting mlflow-skinny<4,>=2.11.3 (from databricks-vectorsearch)\n  Downloading mlflow_skinny-3.8.0-py3-none-any.whl.metadata (31 kB)\nCollecting protobuf<7,>=3.12.0 (from databricks-vectorsearch)\n  Downloading protobuf-6.33.2-cp39-abi3-manylinux2014_aarch64.whl.metadata (593 bytes)\nCollecting requests>=2 (from databricks-vectorsearch)\n  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\nCollecting packaging (from deprecation>=2->databricks-vectorsearch)\n  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\nCollecting cachetools<7,>=5.0.0 (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading cachetools-6.2.4-py3-none-any.whl.metadata (5.6 kB)\nCollecting click<9,>=7.0 (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\nCollecting cloudpickle<4 (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading cloudpickle-3.1.2-py3-none-any.whl.metadata (7.1 kB)\nCollecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading databricks_sdk-0.76.0-py3-none-any.whl.metadata (40 kB)\nCollecting fastapi<1 (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading fastapi-0.127.0-py3-none-any.whl.metadata (30 kB)\nCollecting gitpython<4,>=3.1.9 (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\nCollecting importlib_metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading importlib_metadata-8.7.1-py3-none-any.whl.metadata (4.7 kB)\nCollecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\nCollecting pydantic<3,>=2.0.0 (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\nCollecting python-dotenv<2,>=0.19.0 (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\nCollecting pyyaml<7,>=5.1 (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (2.4 kB)\nCollecting sqlparse<1,>=0.4.0 (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading sqlparse-0.5.5-py3-none-any.whl.metadata (4.7 kB)\nCollecting typing-extensions<5,>=4.0.0 (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\nCollecting uvicorn<1 (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading uvicorn-0.40.0-py3-none-any.whl.metadata (6.7 kB)\nCollecting charset_normalizer<4,>=2 (from requests>=2->databricks-vectorsearch)\n  Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (37 kB)\nCollecting idna<4,>=2.5 (from requests>=2->databricks-vectorsearch)\n  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\nCollecting urllib3<3,>=1.21.1 (from requests>=2->databricks-vectorsearch)\n  Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\nCollecting certifi>=2017.4.17 (from requests>=2->databricks-vectorsearch)\n  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\nCollecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading google_auth-2.45.0-py2.py3-none-any.whl.metadata (6.8 kB)\nCollecting starlette<0.51.0,>=0.40.0 (from fastapi<1->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\nCollecting annotated-doc>=0.0.2 (from fastapi<1->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\nCollecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\nCollecting zipp>=3.20 (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\nCollecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\nCollecting annotated-types>=0.6.0 (from pydantic<3,>=2.0.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\nCollecting pydantic-core==2.41.5 (from pydantic<3,>=2.0.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (7.3 kB)\nCollecting typing-inspection>=0.4.2 (from pydantic<3,>=2.0.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\nCollecting h11>=0.8 (from uvicorn<1->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\nCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\nCollecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\nCollecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\nCollecting anyio<5,>=3.6.2 (from starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\nCollecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch)\n  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\nDownloading databricks_vectorsearch-0.63-py3-none-any.whl (19 kB)\nDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\nDownloading mlflow_skinny-3.8.0-py3-none-any.whl (2.5 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/2.5 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.5/2.5 MB\u001B[0m \u001B[31m51.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading protobuf-6.33.2-cp39-abi3-manylinux2014_aarch64.whl (324 kB)\nDownloading requests-2.32.5-py3-none-any.whl (64 kB)\nDownloading cachetools-6.2.4-py3-none-any.whl (11 kB)\nDownloading certifi-2025.11.12-py3-none-any.whl (159 kB)\nDownloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (148 kB)\nDownloading click-8.3.1-py3-none-any.whl (108 kB)\nDownloading cloudpickle-3.1.2-py3-none-any.whl (22 kB)\nDownloading databricks_sdk-0.76.0-py3-none-any.whl (774 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/774.7 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m774.7/774.7 kB\u001B[0m \u001B[31m38.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading fastapi-0.127.0-py3-none-any.whl (112 kB)\nDownloading gitpython-3.1.45-py3-none-any.whl (208 kB)\nDownloading idna-3.11-py3-none-any.whl (71 kB)\nDownloading importlib_metadata-8.7.1-py3-none-any.whl (27 kB)\nDownloading opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\nDownloading opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\nDownloading opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\nDownloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\nDownloading packaging-25.0-py3-none-any.whl (66 kB)\nDownloading pydantic-2.12.5-py3-none-any.whl (463 kB)\nDownloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.9 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/1.9 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.9/1.9 MB\u001B[0m \u001B[31m94.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\nDownloading pyyaml-6.0.3-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (775 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/775.1 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m775.1/775.1 kB\u001B[0m \u001B[31m34.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading sqlparse-0.5.5-py3-none-any.whl (46 kB)\nDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\nDownloading urllib3-2.6.2-py3-none-any.whl (131 kB)\nDownloading uvicorn-0.40.0-py3-none-any.whl (68 kB)\nDownloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\nDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\nDownloading gitdb-4.0.12-py3-none-any.whl (62 kB)\nDownloading google_auth-2.45.0-py2.py3-none-any.whl (233 kB)\nDownloading h11-0.16.0-py3-none-any.whl (37 kB)\nDownloading starlette-0.50.0-py3-none-any.whl (74 kB)\nDownloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\nDownloading zipp-3.23.0-py3-none-any.whl (10 kB)\nDownloading anyio-4.12.0-py3-none-any.whl (113 kB)\nDownloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\nDownloading rsa-4.9.1-py3-none-any.whl (34 kB)\nDownloading smmap-5.0.2-py3-none-any.whl (24 kB)\nDownloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\nInstalling collected packages: zipp, urllib3, typing-extensions, sqlparse, smmap, pyyaml, python-dotenv, pyasn1, protobuf, packaging, idna, h11, cloudpickle, click, charset_normalizer, certifi, cachetools, annotated-types, annotated-doc, uvicorn, typing-inspection, rsa, requests, pydantic-core, pyasn1-modules, opentelemetry-proto, importlib_metadata, gitdb, deprecation, anyio, starlette, pydantic, opentelemetry-api, google-auth, gitpython, opentelemetry-semantic-conventions, fastapi, databricks-sdk, opentelemetry-sdk, mlflow-skinny, databricks-vectorsearch\n  Attempting uninstall: zipp\n    Found existing installation: zipp 3.23.0\n    Uninstalling zipp-3.23.0:\n      Successfully uninstalled zipp-3.23.0\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 2.6.2\n    Uninstalling urllib3-2.6.2:\n      Successfully uninstalled urllib3-2.6.2\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.15.0\n    Uninstalling typing_extensions-4.15.0:\n      Successfully uninstalled typing_extensions-4.15.0\n  Attempting uninstall: sqlparse\n    Found existing installation: sqlparse 0.5.5\n    Uninstalling sqlparse-0.5.5:\n      Successfully uninstalled sqlparse-0.5.5\n  Attempting uninstall: smmap\n    Found existing installation: smmap 5.0.2\n    Uninstalling smmap-5.0.2:\n      Successfully uninstalled smmap-5.0.2\n  Attempting uninstall: pyyaml\n    Found existing installation: PyYAML 6.0.3\n    Uninstalling PyYAML-6.0.3:\n      Successfully uninstalled PyYAML-6.0.3\n  Attempting uninstall: python-dotenv\n    Found existing installation: python-dotenv 1.2.1\n    Uninstalling python-dotenv-1.2.1:\n      Successfully uninstalled python-dotenv-1.2.1\n  Attempting uninstall: pyasn1\n    Found existing installation: pyasn1 0.6.1\n    Uninstalling pyasn1-0.6.1:\n      Successfully uninstalled pyasn1-0.6.1\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 6.33.2\n    Uninstalling protobuf-6.33.2:\n      Successfully uninstalled protobuf-6.33.2\n  Attempting uninstall: packaging\n    Found existing installation: packaging 25.0\n    Uninstalling packaging-25.0:\n      Successfully uninstalled packaging-25.0\n  Attempting uninstall: idna\n    Found existing installation: idna 3.11\n    Uninstalling idna-3.11:\n      Successfully uninstalled idna-3.11\n  Attempting uninstall: h11\n    Found existing installation: h11 0.16.0\n    Uninstalling h11-0.16.0:\n      Successfully uninstalled h11-0.16.0\n  Attempting uninstall: cloudpickle\n    Found existing installation: cloudpickle 3.1.2\n    Uninstalling cloudpickle-3.1.2:\n      Successfully uninstalled cloudpickle-3.1.2\n  Attempting uninstall: click\n    Found existing installation: click 8.3.1\n    Uninstalling click-8.3.1:\n      Successfully uninstalled click-8.3.1\n  Attempting uninstall: charset_normalizer\n    Found existing installation: charset-normalizer 3.4.4\n    Uninstalling charset-normalizer-3.4.4:\n      Successfully uninstalled charset-normalizer-3.4.4\n  Attempting uninstall: certifi\n    Found existing installation: certifi 2025.11.12\n    Uninstalling certifi-2025.11.12:\n      Successfully uninstalled certifi-2025.11.12\n  Attempting uninstall: cachetools\n    Found existing installation: cachetools 6.2.4\n    Uninstalling cachetools-6.2.4:\n      Successfully uninstalled cachetools-6.2.4\n  Attempting uninstall: annotated-types\n    Found existing installation: annotated-types 0.7.0\n    Uninstalling annotated-types-0.7.0:\n      Successfully uninstalled annotated-types-0.7.0\n  Attempting uninstall: annotated-doc\n    Found existing installation: annotated-doc 0.0.4\n    Uninstalling annotated-doc-0.0.4:\n      Successfully uninstalled annotated-doc-0.0.4\n  Attempting uninstall: uvicorn\n    Found existing installation: uvicorn 0.40.0\n    Uninstalling uvicorn-0.40.0:\n      Successfully uninstalled uvicorn-0.40.0\n  Attempting uninstall: typing-inspection\n    Found existing installation: typing-inspection 0.4.2\n    Uninstalling typing-inspection-0.4.2:\n      Successfully uninstalled typing-inspection-0.4.2\n  Attempting uninstall: rsa\n    Found existing installation: rsa 4.9.1\n    Uninstalling rsa-4.9.1:\n      Successfully uninstalled rsa-4.9.1\n  Attempting uninstall: requests\n    Found existing installation: requests 2.32.5\n    Uninstalling requests-2.32.5:\n      Successfully uninstalled requests-2.32.5\n  Attempting uninstall: pydantic-core\n    Found existing installation: pydantic_core 2.41.5\n    Uninstalling pydantic_core-2.41.5:\n      Successfully uninstalled pydantic_core-2.41.5\n  Attempting uninstall: pyasn1-modules\n    Found existing installation: pyasn1_modules 0.4.2\n    Uninstalling pyasn1_modules-0.4.2:\n      Successfully uninstalled pyasn1_modules-0.4.2\n  Attempting uninstall: opentelemetry-proto\n    Found existing installation: opentelemetry-proto 1.39.1\n    Uninstalling opentelemetry-proto-1.39.1:\n      Successfully uninstalled opentelemetry-proto-1.39.1\n  Attempting uninstall: importlib_metadata\n    Found existing installation: importlib_metadata 8.7.1\n    Uninstalling importlib_metadata-8.7.1:\n      Successfully uninstalled importlib_metadata-8.7.1\n  Attempting uninstall: gitdb\n    Found existing installation: gitdb 4.0.12\n    Uninstalling gitdb-4.0.12:\n      Successfully uninstalled gitdb-4.0.12\n  Attempting uninstall: deprecation\n    Found existing installation: deprecation 2.1.0\n    Uninstalling deprecation-2.1.0:\n      Successfully uninstalled deprecation-2.1.0\n  Attempting uninstall: anyio\n    Found existing installation: anyio 4.12.0\n    Uninstalling anyio-4.12.0:\n      Successfully uninstalled anyio-4.12.0\n  Attempting uninstall: starlette\n    Found existing installation: starlette 0.50.0\n    Uninstalling starlette-0.50.0:\n      Successfully uninstalled starlette-0.50.0\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 2.12.5\n    Uninstalling pydantic-2.12.5:\n      Successfully uninstalled pydantic-2.12.5\n  Attempting uninstall: opentelemetry-api\n    Found existing installation: opentelemetry-api 1.39.1\n    Uninstalling opentelemetry-api-1.39.1:\n      Successfully uninstalled opentelemetry-api-1.39.1\n  Attempting uninstall: google-auth\n    Found existing installation: google-auth 2.45.0\n    Uninstalling google-auth-2.45.0:\n      Successfully uninstalled google-auth-2.45.0\n  Attempting uninstall: gitpython\n    Found existing installation: GitPython 3.1.45\n    Uninstalling GitPython-3.1.45:\n      Successfully uninstalled GitPython-3.1.45\n  Attempting uninstall: opentelemetry-semantic-conventions\n    Found existing installation: opentelemetry-semantic-conventions 0.60b1\n    Uninstalling opentelemetry-semantic-conventions-0.60b1:\n      Successfully uninstalled opentelemetry-semantic-conventions-0.60b1\n  Attempting uninstall: fastapi\n    Found existing installation: fastapi 0.127.0\n    Uninstalling fastapi-0.127.0:\n      Successfully uninstalled fastapi-0.127.0\n  Attempting uninstall: databricks-sdk\n    Found existing installation: databricks-sdk 0.76.0\n    Uninstalling databricks-sdk-0.76.0:\n      Successfully uninstalled databricks-sdk-0.76.0\n  Attempting uninstall: opentelemetry-sdk\n    Found existing installation: opentelemetry-sdk 1.39.1\n    Uninstalling opentelemetry-sdk-1.39.1:\n      Successfully uninstalled opentelemetry-sdk-1.39.1\n  Attempting uninstall: mlflow-skinny\n    Found existing installation: mlflow-skinny 3.8.0\n    Uninstalling mlflow-skinny-3.8.0:\n      Successfully uninstalled mlflow-skinny-3.8.0\n  Attempting uninstall: databricks-vectorsearch\n    Found existing installation: databricks-vectorsearch 0.63\n    Uninstalling databricks-vectorsearch-0.63:\n      Successfully uninstalled databricks-vectorsearch-0.63\n\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-api-core 2.20.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5, but you have protobuf 6.33.2 which is incompatible.\ngoogleapis-common-protos 1.65.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 6.33.2 which is incompatible.\ngrpcio-status 1.67.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.33.2 which is incompatible.\nhttpcore 1.0.2 requires h11<0.15,>=0.13, but you have h11 0.16.0 which is incompatible.\npyiceberg 0.9.0 requires cachetools<6.0.0,>=5.5.0, but you have cachetools 6.2.4 which is incompatible.\u001B[0m\u001B[31m\n\u001B[0mSuccessfully installed annotated-doc-0.0.4 annotated-types-0.7.0 anyio-4.12.0 cachetools-6.2.4 certifi-2025.11.12 charset_normalizer-3.4.4 click-8.3.1 cloudpickle-3.1.2 databricks-sdk-0.76.0 databricks-vectorsearch-0.63 deprecation-2.1.0 fastapi-0.127.0 gitdb-4.0.12 gitpython-3.1.45 google-auth-2.45.0 h11-0.16.0 idna-3.11 importlib_metadata-8.7.1 mlflow-skinny-3.8.0 opentelemetry-api-1.39.1 opentelemetry-proto-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 packaging-25.0 protobuf-6.33.2 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.12.5 pydantic-core-2.41.5 python-dotenv-1.2.1 pyyaml-6.0.3 requests-2.32.5 rsa-4.9.1 smmap-5.0.2 sqlparse-0.5.5 starlette-0.50.0 typing-extensions-4.15.0 typing-inspection-0.4.2 urllib3-2.6.2 uvicorn-0.40.0 zipp-3.23.0\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --force-reinstall databricks-vectorsearch\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85b81ce3-5679-4da1-b2c4-123276372e3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load Vector Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5588ce6-f0d4-4443-9582-d0160f8cf493",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "\n",
    "vsc = VectorSearchClient(disable_notice=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "03cfbdbb-8de3-4b3a-9b2e-53ff4e33d587",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'name': 'widlchat',\n",
       " 'creator': 'ammarbagharib@gmail.com',\n",
       " 'creation_timestamp': 1765100413443,\n",
       " 'last_updated_timestamp': 1765100413443,\n",
       " 'endpoint_type': 'STANDARD',\n",
       " 'last_updated_user': 'ammarbagharib@gmail.com',\n",
       " 'id': '7bdb1ad1-2826-409a-a18b-517bc84e8a6e',\n",
       " 'endpoint_status': {'state': 'ONLINE'},\n",
       " 'num_indexes': 1,\n",
       " 'throughput_info': {'requested_concurrency': 2.0,\n",
       "  'current_concurrency': 2.0,\n",
       "  'current_concurrency_utilization_percentage': 5.0,\n",
       "  'change_request_state': 'CHANGE_SUCCESS',\n",
       "  'requested_num_replicas': 1,\n",
       "  'current_num_replicas': 1}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_search_endpoint_name = \"widlchat\"\n",
    "vsc.get_endpoint(\n",
    "  name=vector_search_endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6325d356-cd8a-45a8-aeda-9314bd384997",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'name': 'workspace.gold.idx_convos_classified',\n",
       " 'endpoint_name': 'widlchat',\n",
       " 'primary_key': 'conversation_id',\n",
       " 'index_type': 'DELTA_SYNC',\n",
       " 'delta_sync_index_spec': {'source_table': 'workspace.gold.index_creation',\n",
       "  'embedding_source_columns': [{'name': 'combined_text',\n",
       "    'embedding_model_endpoint_name': 'databricks-gte-large-en'}],\n",
       "  'pipeline_type': 'TRIGGERED',\n",
       "  'pipeline_id': 'f76d1067-b191-4461-b47a-3667c53b9831'},\n",
       " 'status': {'detailed_state': 'ONLINE_TRIGGERED_UPDATE',\n",
       "  'message': 'Index creation succeeded. Check latest status: https://dbc-dbab8434-5a1d.cloud.databricks.com/explore/data/workspace/gold/idx_convos_classified',\n",
       "  'indexed_row_count': 660,\n",
       "  'triggered_update_status': {'last_processed_commit_version': 3,\n",
       "   'last_processed_commit_timestamp': '2025-12-22T16:03:31Z',\n",
       "   'triggered_update_progress': {'latest_version_currently_processing': 4,\n",
       "    'num_synced_rows': 450,\n",
       "    'total_rows_to_sync': 5076,\n",
       "    'sync_progress_completion': 0.0887,\n",
       "    'estimated_completion_time_seconds': 4354.9044,\n",
       "    'pipeline_metrics': {'total_sync_time_per_row_ms': 941.9511,\n",
       "     'ingestion_metrics': {'ingestion_time_per_row_ms': 4.8022,\n",
       "      'ingestion_batch_size': 50},\n",
       "     'embedding_metrics': {'embedding_generation_time_per_row_ms': 919.1844,\n",
       "      'embedding_generation_batch_size': 5}}}},\n",
       "  'ready': True,\n",
       "  'index_url': 'dbc-dbab8434-5a1d.cloud.databricks.com/api/2.0/vector-search/indexes/workspace.gold.idx_convos_classified'},\n",
       " 'creator': 'ammarbagharib@gmail.com',\n",
       " 'endpoint_type': 'STANDARD',\n",
       " 'id': '2514bbdf-c53d-4af5-bf76-b0e93930179f'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overview tab for the vector index.\n",
    "vs_index_fullname = \"workspace.gold.idx_convos_classified\"\n",
    "index = vsc.get_index(endpoint_name=vector_search_endpoint_name,index_name=vs_index_fullname)\n",
    "index.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3114fa46-9111-4645-a764-4d1a1497dacb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Semantic classification function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0c9b8ed-4151-42a8-98ed-e1f1e6f089eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2dd3444-db72-4ae8-b353-9587c22860d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load data and classify\n",
    "df_gold_summarized = spark.table(\"gold.conversations_summarized\")\n",
    "\n",
    "df_gold_summarized_sampled = (\n",
    "    df_gold_summarized\n",
    "    .orderBy(F.rand())\n",
    "    .limit(5000)\n",
    ")\n",
    "\n",
    "df_gold_summarized_sampled.createOrReplaceTempView(\"sampled_src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6afa961-84f4-4708-bd6e-274b8ac625d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.execution_warning": {
       "execution_timeout": 9000.0,
       "start_time": 1.766510639855795E9,
       "timeout_extension_enabled": true,
       "warning_threshold": 300.0
      },
      "text/plain": [
       "\u001B[0;33mWARNING: Your spark query has been running for more than 5 minutes. Your interactive serverless execution timeout is set to 150 minutes. Any single spark query that lasts longer than this timeout will be canceled. You can modify the timeout by running `spark.conf.set('spark.databricks.execution.timeout', timeout)`.\u001B[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_semantic_classified = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  src.conversation_id,\n",
    "  src.ISID,\n",
    "  src.country,\n",
    "  src.combined_text,\n",
    "  src.char_count,\n",
    "  src.convo_summary,\n",
    "\n",
    "  -- semantic hit → category, else empty\n",
    "  CASE\n",
    "    WHEN vs.search_score >= 0.75 THEN vs.top_category\n",
    "    ELSE ''\n",
    "  END AS top_category,\n",
    "\n",
    "  -- semantic hit → similarity score, else 0.0\n",
    "  CASE\n",
    "    WHEN vs.search_score >= 0.75 THEN vs.search_score\n",
    "    ELSE 0.0\n",
    "  END AS similarity_score,\n",
    "\n",
    "  -- semantic hit → 'semantic', else empty\n",
    "  CASE\n",
    "    WHEN vs.search_score >= 0.75 THEN 'semantic'\n",
    "    ELSE ''\n",
    "  END AS classification_method\n",
    "\n",
    "FROM sampled_src src\n",
    "\n",
    "LEFT JOIN LATERAL (\n",
    "  SELECT\n",
    "    result.top_category,\n",
    "    result.search_score\n",
    "  FROM vector_search(\n",
    "    index => 'workspace.gold.idx_convos_classified',\n",
    "    query_text => src.combined_text,\n",
    "    num_results => 1\n",
    "  ) AS result\n",
    ") vs\n",
    "\"\"\")\n",
    "\n",
    "# spark.sql(\"DROP TABLE gold.conversations_semantic_classified\")\n",
    "df_semantic_classified.write.mode(\"overwrite\").saveAsTable(\n",
    "    \"gold.conversations_semantic_classified\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db2c6414-00f6-4ce6-933b-aba7fedf286b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----+\n|classification_method|count|\n+---------------------+-----+\n|                     | 4976|\n|             semantic|   24|\n+---------------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "spark.table(\"gold.conversations_semantic_classified\") \\\n",
    "     .groupBy(\"classification_method\") \\\n",
    "     .count() \\\n",
    "     .orderBy(F.desc(\"count\")) \\\n",
    "     .show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "gold_semantic_classification",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}