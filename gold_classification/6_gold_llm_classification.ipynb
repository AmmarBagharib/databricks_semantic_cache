{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10179c09-0eb8-4cb9-a442-bc7ed69d6035",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "584ff972-9c0f-470a-969a-8deaac3efae4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_semantic_classified = spark.table(\"gold.conversations_semantic_classified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5912be5a-1060-4f6d-8986-4c4b96736470",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Save categories_list to JSON file"
    }
   },
   "outputs": [],
   "source": [
    "with open('/Workspace/Users/ammarbagharib@gmail.com/categories_list.json', 'r') as f:\n",
    "    categories_list = json.load(f)\n",
    "print(categories_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf9b265f-c5a1-4d27-9d3f-006d71f523da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Apply ai_classify\n",
    "df_classified = (\n",
    "    df_semantic_classified\n",
    "    .filter(F.col(\"classification_method\") != \"semantic\")\n",
    "    .select(\n",
    "        \"conversation_id\",\n",
    "        \"ISID\",\n",
    "        \"country\",\n",
    "        \"combined_text\",\n",
    "        \"convo_summary\",\n",
    "        \"char_count\",\n",
    "        F.expr(f\"\"\"\n",
    "            ai_classify(\n",
    "                combined_text,\n",
    "                array({','.join([f'\"{c}\"' for c in categories_list])})\n",
    "            )\n",
    "        \"\"\").alias(\"top_category\"),\n",
    "        F.lit(\"llm\").alias(\"classification_method\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Get semantic classified rows\n",
    "df_semantic = (\n",
    "    df_semantic_classified\n",
    "    .filter(F.col(\"classification_method\") == \"semantic\")\n",
    "    .select(\n",
    "        \"conversation_id\",\n",
    "        \"ISID\",\n",
    "        \"country\",\n",
    "        \"combined_text\",\n",
    "        \"convo_summary\",\n",
    "        \"char_count\",\n",
    "        F.col(\"top_category\"),\n",
    "        \"classification_method\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Union both DataFrames\n",
    "df_classified_all = df_classified.unionByName(df_semantic)\n",
    "\n",
    "# Write to table\n",
    "spark.sql(\"DROP TABLE gold.conversations_classified\")\n",
    "df_classified_all.write.mode(\"overwrite\").saveAsTable(\"gold.conversations_classified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ed31f03-2515-4537-91c0-2f9c2fd47ced",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# display(df_classified)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "gold_llm_classification",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}