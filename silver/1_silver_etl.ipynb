{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9118bbd8-0197-48eb-949f-674a455a651f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql import Window\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07394fc5-a176-4928-9515-a06f81f2c529",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load Bronze\n",
    "bronze_df = spark.table(\"bronze.conversations\")\n",
    "bronze_df_sampled = (\n",
    "    bronze_df\n",
    "    .filter(F.col(\"language\") == \"English\")\n",
    "    .orderBy(F.rand())\n",
    "    .limit(10000)\n",
    ")\n",
    "# display(bronze_df_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8757c4b8-f6d1-4c3a-b745-4d6d7315ffda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 1. EXPLODE TURNS & LIMIT TO 50\n",
    "# -------------------------\n",
    "df_turns = (\n",
    "    bronze_df_sampled\n",
    "        .select(\n",
    "            \"conversation_id\",\n",
    "            \"language\",\n",
    "            \"timestamp\",\n",
    "            F.posexplode(\"conversation\").alias(\"turn_idx\", \"turn_struct\")\n",
    "        )\n",
    "        .withColumn(\"role\", F.col(\"turn_struct.role\"))\n",
    "        .withColumn(\"content\", F.col(\"turn_struct.content\"))\n",
    "        .drop(\"turn_struct\")\n",
    ")\n",
    "\n",
    "# Keep only first 50 turns per conversation_id\n",
    "window_turns = (\n",
    "    Window.partitionBy(\"conversation_id\")\n",
    "          .orderBy(\"turn_idx\")\n",
    ")\n",
    "\n",
    "df_turns_50 = (\n",
    "    df_turns\n",
    "       .withColumn(\"rn\", F.row_number().over(window_turns))\n",
    "       .filter(F.col(\"rn\") <= 50)\n",
    "       .drop(\"rn\")\n",
    ")\n",
    "# display(df_turns_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c86192d-8a3a-4eff-95cd-c85269020096",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 2. TRUNCATE EACH TURN\n",
    "# -------------------------\n",
    "MAX_CHARS = 250 \n",
    "\n",
    "df_truncated = (\n",
    "    df_turns_50\n",
    "        .withColumn(\"char_count\", F.length(F.col(\"content\")))\n",
    "        .withColumn(\n",
    "            \"content_truncated\",\n",
    "            F.when(F.length(F.col(\"content\")) > MAX_CHARS,\n",
    "                   F.substring(F.col(\"content\"), 1, MAX_CHARS)\n",
    "            ).otherwise(F.col(\"content\"))\n",
    "        )\n",
    ")\n",
    "\n",
    "# display(df_truncated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87ae0666-0b93-4014-a6b5-0b6161fd9578",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_truncated.write.mode(\"overwrite\").saveAsTable(\"silver.chat_turns_truncated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4228b2a4-2f0f-4cfb-a83f-0428d407aa5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_conv = spark.table(\"silver.chat_turns_truncated\")\n",
    "\n",
    "df_conversations = (\n",
    "    df_conv\n",
    "        .groupBy(\"conversation_id\")\n",
    "        .agg(\n",
    "            F.collect_list(\n",
    "                F.struct(\n",
    "                    \"turn_idx\",\n",
    "                    \"role\",\n",
    "                    \"content_truncated\",\n",
    "                    \"char_count\"\n",
    "                )\n",
    "            ).alias(\"turns\"),\n",
    "            F.first(\"language\").alias(\"language\"),\n",
    "            F.max(\"timestamp\").alias(\"timestamp\"),\n",
    "            F.sum(\"char_count\").alias(\"conversation_char_count_total\")\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"turns\",\n",
    "            F.expr(\"array_sort(turns, (left, right) -> CASE WHEN left.turn_idx < right.turn_idx THEN -1 WHEN left.turn_idx > right.turn_idx THEN 1 ELSE 0 END)\")\n",
    "        )\n",
    ")\n",
    "\n",
    "#display(df_conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f44f9fc1-8c02-438b-9854-4c96791c44b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_conversations.write.mode(\"overwrite\").saveAsTable(\"silver.conversations_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a3eee19-ed86-466c-8cbb-3fe7461afa57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/pyspark/sql/connect/expressions.py:1134: UserWarning: WARN WindowExpression: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## SYNTHETIC USER ISID CREATION\n",
    "# We create approximately 5 conversations per user\n",
    "CONV_PER_USER = 5\n",
    "\n",
    "df_isid = (\n",
    "    df_conversations\n",
    "        .withColumn(\"rand\", F.rand(seed=42))\n",
    "        .withColumn(\"row_num\", F.row_number().over(Window.orderBy(\"rand\")))\n",
    "        .withColumn(\"ISID\", (F.col(\"row_num\") / CONV_PER_USER).cast(\"int\"))\n",
    "        .withColumn(\"ISID\", F.concat(F.lit(\"user_\"), F.col(\"ISID\")))\n",
    "        .select(\"conversation_id\", \"ISID\")\n",
    ")\n",
    "\n",
    "df_isid.write.mode(\"overwrite\").saveAsTable(\"silver.synthetic_isid_mapping\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3b3142c-5484-478f-b6ef-2e927e897715",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/pyspark/sql/connect/expressions.py:1134: UserWarning: WARN WindowExpression: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## SYNTHETIC COUNTRY MAPPING CREATION\n",
    "# Define countries with realistic distribution weights\n",
    "countries = [\n",
    "    (\"United States\", 30),\n",
    "    (\"United Kingdom\", 15),\n",
    "    (\"Canada\", 10),\n",
    "    (\"Germany\", 8),\n",
    "    (\"France\", 7),\n",
    "    (\"Australia\", 6),\n",
    "    (\"India\", 5),\n",
    "    (\"Japan\", 4),\n",
    "    (\"Brazil\", 4),\n",
    "    (\"Spain\", 3),\n",
    "    (\"Italy\", 3),\n",
    "    (\"Netherlands\", 2),\n",
    "    (\"Singapore\", 2),\n",
    "    (\"Mexico\", 1)\n",
    "]\n",
    "\n",
    "# Create weighted country assignment UDF\n",
    "@F.udf(\"string\")\n",
    "def assign_country(isid):\n",
    "    random.seed(hash(isid) % (2**32))  # Deterministic based on ISID\n",
    "    country_list = [c for c, weight in countries for _ in range(weight)]\n",
    "    return random.choice(country_list)\n",
    "\n",
    "# Get unique ISIDs and assign countries\n",
    "df_isid_country = (\n",
    "    df_isid\n",
    "        .select(\"ISID\")\n",
    "        .distinct()\n",
    "        .withColumn(\"country\", assign_country(\"ISID\"))\n",
    ")\n",
    "\n",
    "# Save the mapping\n",
    "df_isid_country.write.mode(\"overwrite\").saveAsTable(\"gold.synthetic_country_mapping\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_etl",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}